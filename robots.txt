# robots.txt for DevRadar Open Research
# Last Updated: 2026-01-20

# -------------------------------------------------
# General Crawler Policy (All Bots)
# -------------------------------------------------
User-agent: *
Allow: /

# Disallow private/sensitive directories
Disallow: /_site/
Disallow: /.git/
Disallow: /.sass-cache/
Disallow: /.jekyll-cache/
Disallow: /vendor/
Disallow: /node_modules/

# Disallow development files (not in production)
Disallow: /CLAUDE.md
Disallow: /Gemfile
Disallow: /Gemfile.lock
Disallow: /LICENSE
Disallow: /README.md

# Crawl-delay for respectful crawling
Crawl-delay: 1

# -------------------------------------------------
# AI Search Agents (2026)
# -------------------------------------------------
# OpenAI GPTBot - Allow with restrictions
User-agent: GPTBot
Allow: /
Crawl-delay: 1

# Google-Extended (AI training)
User-agent: Google-Extended
Disallow: /

# Claude Anthropic AI
User-agent: Claude-Web
Allow: /
Crawl-delay: 1

# Common Crawl (used for AI training)
User-agent: CCBot
Allow: /
Crawl-delay: 1

# -------------------------------------------------
# Sitemap Location
# -------------------------------------------------
Sitemap: https://devradar-dev.github.io/open-research/sitemap.xml
